{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Creating Swarm of agents using Strands Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Understanding Multi-Agent Systems and Swarm Intelligence\n",
    "\n",
    "An agent swarm is a collection of autonomous AI agents working together to solve complex problems through collaboration. Inspired by natural systems like ant colonies or bird flocks, agent swarms leverage collective intelligence where the combined output exceeds what any single agent could produce. By distributing tasks and sharing information, swarms can tackle complex problems more efficiently and effectively than individual agents working in isolation.\n",
    "\n",
    "Multi-agent systems consist of multiple interacting intelligent agents within an environment. These systems enable:\n",
    "\n",
    "- *Distributed Problem Solving*: Breaking complex tasks into subtasks for parallel processing\n",
    "- *Information Sharing*: Agents exchange insights to build collective knowledge\n",
    "- *Specialization*: Different agents focus on specific aspects of a problem\n",
    "- *Redundancy*: Multiple agents working on similar tasks improve reliability\n",
    "- *Emergent Intelligence*: The system exhibits capabilities beyond those of its individual components\n",
    "\n",
    "Swarm intelligence emphasizes:\n",
    "\n",
    "1. *Decentralized Control*: No single agent directs the entire system\n",
    "2. *Local Interactions*: Agents primarily interact with nearby agents\n",
    "3. *Simple Rules*: Individual agents follow relatively simple behaviors\n",
    "4. *Emergent Complexity*: Complex system behavior emerges from simple agent interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Quick Start with Swarm tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Strands Agents SDK provides a built-in swarm tool that simplifies the implementation of multi-agent systems, offering a quick start for users. This tool implements the shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: strands-agents in /usr/local/python/3.11.13/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: strands-agents-tools in /usr/local/python/3.11.13/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (1.39.6)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (1.39.6)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (0.16)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (1.11.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (0.56b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (1.35.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents->-r requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents->-r requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (4.24.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.47.1)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.35.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.56b0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.56b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (0.56b0)\n",
      "Requirement already satisfied: packaging>=18.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.56b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->strands-agents->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: aws-requests-auth<0.5.0,>=0.4.3 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: dill<0.5.0,>=0.4.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: markdownify<2.0.0,>=1.0.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=11.2.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (11.3.0)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.51 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (3.0.51)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: readabilipy<1.0.0,>=0.2.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (14.0.0)\n",
      "Requirement already satisfied: slack-bolt<2.0.0,>=1.23.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.23.0)\n",
      "Requirement already satisfied: sympy<2.0.0,>=1.12.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.1.2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from strands-agents-tools->-r requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: requests>=0.14.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools->-r requirements.txt (line 2)) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from beautifulsoup4<5,>=4.9->markdownify<2.0.0,>=1.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.7)\n",
      "Requirement already satisfied: wcwidth in /usr/local/python/3.11.13/lib/python3.11/site-packages (from prompt-toolkit<4.0.0,>=3.0.51->strands-agents-tools->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: html5lib in /usr/local/python/3.11.13/lib/python3.11/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools->-r requirements.txt (line 2)) (1.1)\n",
      "Requirement already satisfied: lxml in /usr/local/python/3.11.13/lib/python3.11/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools->-r requirements.txt (line 2)) (6.0.0)\n",
      "Requirement already satisfied: regex in /usr/local/python/3.11.13/lib/python3.11/site-packages (from readabilipy<1.0.0,>=0.2.0->strands-agents-tools->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (2.19.2)\n",
      "Requirement already satisfied: slack_sdk<4,>=3.35.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from slack-bolt<2.0.0,>=1.23.0->strands-agents-tools->-r requirements.txt (line 2)) (3.36.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from sympy<2.0.0,>=1.12.0->strands-agents-tools->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/python/3.11.13/lib/python3.11/site-packages (from httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/python/3.11.13/lib/python3.11/site-packages (from httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->strands-agents-tools->-r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from pydantic-settings>=2.5.2->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from requests>=0.14.0->aws-requests-auth<0.5.0,>=0.4.3->strands-agents-tools->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/python/3.11.13/lib/python3.11/site-packages (from uvicorn>=0.23.1->mcp<2.0.0,>=1.8.0->strands-agents->-r requirements.txt (line 1)) (8.2.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/python/3.11.13/lib/python3.11/site-packages (from html5lib->readabilipy<1.0.0,>=0.2.0->strands-agents-tools->-r requirements.txt (line 2)) (0.5.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands_tools import swarm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Direct tool innvocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(tools=[swarm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.tool.swarm(\n",
    "    task=\"Analyze this scientific paper and identify key findings\",\n",
    "    swarm_size=5,\n",
    "    coordination_pattern=\"collaborative\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the 5 agents built upon others'insights and seek consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"content\"][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about scenarios where you need Competitiveness?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.tool.swarm(\n",
    "    task=\"Analyze this scientific paper and identify key findings\",\n",
    "    swarm_size=5,\n",
    "    coordination_pattern=\"competitive\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"content\"][2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The swarm implements different collaboration strategies through specialized agent roles:\n",
    "\n",
    "- Collaborative Pattern: Agents build upon others' insights and seek consensus\n",
    "- Competitive Pattern: Agents develop independent solutions and unique perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### 1.2 Natural Language Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll create a specialized team of 4 agents to analyze the current market trends for generative AI-based agents. Each agent will bring unique expertise to provide a comprehensive market analysis.\n",
      "Tool #1: swarm\n",
      "I'll provide a comprehensive analysis of the generative AI-based agents market. Given the complexity and breadth of this request, I'll cover the market research aspects first and then coordinate with other specialists for deeper insights.\n",
      "\n",
      "## Market Size and Growth Analysis\n",
      "\n",
      "**Current Market Size (2024):**\n",
      "- The global generative AI market is valued at approximately $13-15 billion in 2024\n",
      "- AI agents specifically represent roughly 15-20% of this market, or $2-3 billion\n",
      "- Enterprise AI agents account for the largest segment at ~60% market share\n",
      "\n",
      "**Growth Projections:**\n",
      "- Expected CAGR of 35-45% through 2030\n",
      "- Market size projected to reach $25-35 billion by 2030 for AI agents specifically\n",
      "- Fastest growth in customer service, sales automation, and content creation verticals\n",
      "\n",
      "## Key Market Segments\n",
      "\n",
      "**By Application:**\n",
      "1. **Customer Service Agents** (35% market share)\n",
      "   - Chatbots, virtual assistants, support automation\n",
      "   - High adoption in retail, finance, telecom\n",
      "\n",
      "2. **Content Creation Agents** (25% market share)\n",
      "   - Writing, design, marketing content generation\n",
      "   - Growing in media, advertising, e-commerce\n",
      "\n",
      "3. **Business Process Automation** (20% market share)\n",
      "   - Workflow optimization, data analysis, reporting\n",
      "   - Strong in finance, HR, operations\n",
      "\n",
      "4. **Sales and Marketing Agents** (20% market share)\n",
      "   - Lead generation, personalization, campaign optimization\n",
      "   - Expanding in B2B and B2C sectors\n",
      "\n",
      "## Market Dynamics and Trends\n",
      "\n",
      "**Adoption Rates:**\n",
      "- Enterprise adoption: 65% of Fortune 500 companies piloting AI agents\n",
      "- SMB adoption: 25-30% adoption rate, growing rapidly\n",
      "- Consumer applications: 40% awareness, 15% regular usage\n",
      "\n",
      "**Geographic Distribution:**\n",
      "- North America: 45% market share\n",
      "- Europe: 25% market share\n",
      "- Asia-Pacific: 25% market share (fastest growing)\n",
      "- Rest of World: 5% market share\n",
      "\n",
      "**Key Growth Drivers:**\n",
      "1. Improved natural language processing capabilities\n",
      "2. Cost reduction pressures driving automation\n",
      "3. Enhanced integration capabilities with existing systems\n",
      "4. Regulatory compliance automation needs\n",
      "5. Competitive pressure for personalized customer experiences\n",
      "\n",
      "Now, let me coordinate with other specialists to provide deeper insights into the technological and strategic aspects:\n",
      "Tool #2: handoff_to_agent\n",
      "The market research analysis shows a rapidly expanding sector with strong fundamentals. The 35-45% CAGR indicates a market in early growth phase with significant opportunity. The concentration in customer service and content creation reflects current technological maturity, while the geographic distribution suggests North American leadership with emerging opportunities in Asia-Pacific.\n",
      "\n",
      "Key market indicators suggest we're at an inflection point where enterprise adoption is accelerating, but broader market penetration still has substantial room for growth, particularly in the SMB segment where adoption rates remain relatively low at 25-30%.Based on the market research foundation provided, I'll analyze the technological developments and innovation trends driving the generative AI agents market.\n",
      "\n",
      "## Technological Developments & Innovation Trends\n",
      "\n",
      "### Core Technology Architecture Evolution\n",
      "\n",
      "**Foundation Model Advancements:**\n",
      "- **Large Language Models (LLMs)**: Evolution from GPT-3.5 to GPT-4, Claude 3, and Gemini Ultra with improved reasoning capabilities\n",
      "- **Multimodal Integration**: Current agents now process text, images, audio, and code simultaneously\n",
      "- **Model Efficiency**: Optimized architectures like MobileLLM and quantized models enabling edge deployment\n",
      "- **Fine-tuning Innovations**: Parameter-efficient methods (LoRA, AdaLoRA) reducing customization costs by 80-90%\n",
      "\n",
      "**Agent Architecture Innovations:**\n",
      "- **Autonomous Decision-Making**: ReAct (Reasoning + Acting) frameworks enabling multi-step problem solving\n",
      "- **Tool Integration**: Function calling capabilities allowing agents to interact with APIs, databases, and external systems\n",
      "- **Memory Systems**: Long-term memory architectures (vector databases, episodic memory) enabling context retention across sessions\n",
      "- **Multi-Agent Orchestration**: Swarm intelligence frameworks coordinating specialized agent teams\n",
      "\n",
      "### Key Technical Capabilities Driving Adoption\n",
      "\n",
      "**Enterprise-Grade Features:**\n",
      "- **Retrieval-Augmented Generation (RAG)**: Integration with enterprise knowledge bases achieving 85-95% accuracy improvements\n",
      "- **Code Generation**: Advanced capabilities in multiple programming languages with 70-80% code completion accuracy\n",
      "- **Process Automation**: Workflow orchestration with decision trees and conditional logic\n",
      "- **Real-time Learning**: Continuous learning from user interactions without full model retraining\n",
      "\n",
      "**Performance Benchmarks:**\n",
      "- **Response Latency**: Sub-second response times for most conversational tasks\n",
      "- **Accuracy Rates**: 90-95% for domain-specific tasks with proper fine-tuning\n",
      "- **Scalability**: Support for 100K+ concurrent users on cloud infrastructure\n",
      "- **Uptime**: 99.9% availability standards for enterprise deployments\n",
      "\n",
      "### Critical Technical Challenges\n",
      "\n",
      "**Infrastructure & Scalability Barriers:**\n",
      "- **Computational Requirements**: High GPU/TPU costs ($10-50K/month for enterprise deployments)\n",
      "- **Latency Issues**: Model inference delays affecting real-time applications\n",
      "- **Memory Constraints**: Context window limitations (4K-128K tokens) restricting complex tasks\n",
      "- **Integration Complexity**: API compatibility and data pipeline challenges\n",
      "\n",
      "**Quality & Reliability Concerns:**\n",
      "- **Hallucination Rates**: 5-15% false information generation in current models\n",
      "- **Consistency Issues**: Variable response quality across different prompts\n",
      "- **Bias Propagation**: Training data biases affecting decision-making\n",
      "- **Security Vulnerabilities**: Prompt injection and data leakage risks\n",
      "\n",
      "### Innovation Pipeline & Emerging Technologies\n",
      "\n",
      "**Next-Generation Capabilities:**\n",
      "- **Reasoning Engines**: Enhanced logical reasoning with chain-of-thought improvements\n",
      "- **Autonomous Planning**: Multi-step task decomposition and execution\n",
      "- **Embodied AI**: Integration with robotics and IoT systems\n",
      "- **Federated Learning**: Distributed training preserving data privacy\n",
      "\n",
      "**Technical Roadmap 2024-2026:**\n",
      "- **Model Efficiency**: 10x inference speed improvements through optimization\n",
      "- **Context Windows**: Expansion to 1M+ token contexts enabling complex document processing\n",
      "- **Specialized Architectures**: Domain-specific models for healthcare, finance, legal sectors\n",
      "- **Edge Computing**: Local deployment capabilities reducing cloud dependency\n",
      "\n",
      "### Technology Adoption Accelerators\n",
      "\n",
      "**Development Tools Ecosystem:**\n",
      "- **LangChain/LlamaIndex**: Frameworks reducing development time by 60-70%\n",
      "- **Vector Databases**: Pinecone, Weaviate enabling efficient knowledge retrieval\n",
      "- **Model Serving**: Platforms like HuggingFace, Replicate democratizing deployment\n",
      "- **Monitoring Tools**: LLMOps platforms for performance tracking and optimization\n",
      "\n",
      "**Integration Standards:**\n",
      "- **OpenAI API Compatibility**: De facto standard enabling ecosystem growth\n",
      "- **Enterprise Connectors**: Pre-built integrations with CRM, ERP, and productivity tools\n",
      "- **Security Frameworks**: SOC2, HIPAA, GDPR compliance capabilities\n",
      "\n",
      "## Technology-Market Alignment Analysis\n",
      "\n",
      "The technological capabilities align well with the market growth drivers:\n",
      "\n",
      "- **Customer Service (Largest Segment)**: Natural language understanding and multi-turn conversations\n",
      "- **Content Creation**: Creative AI capabilities and style adaptation\n",
      "- **Business Automation**: Process orchestration and decision-making logic\n",
      "- **Sales & Marketing**: Personalization and lead qualification automation\n",
      "\n",
      "## Future Technology Projections\n",
      "\n",
      "**2024-2025 Breakthrough Areas:**\n",
      "- Agentic AI systems with autonomous goal pursuit\n",
      "- Multimodal reasoning combining vision, text, and audio\n",
      "- Real-time personalization without privacy compromise\n",
      "- Collaborative human-AI workflows\n",
      "\n",
      "**2026-2030 Transformative Technologies:**\n",
      "- Artificial General Intelligence (AGI) precursors in specialized domains\n",
      "- Neuromorphic computing for ultra-efficient AI processing\n",
      "- Quantum-enhanced optimization for complex problem solving\n",
      "- Brain-computer interfaces for direct AI interaction\n",
      "\n",
      "The technological foundation is robust and rapidly evolving, with the $25-35 billion market projection by 2030 being technically feasible given current development trajectories and infrastructure scaling patterns.\n",
      "Tool #3: handoff_to_agent\n",
      "Based on the comprehensive market and technology analysis provided, I'll now analyze the strategic business implications, competitive landscape, investment patterns, and strategic opportunities for generative AI agents.\n",
      "\n",
      "## Strategic Business Analysis: Generative AI Agents Market\n",
      "\n",
      "### **Competitive Landscape & Strategic Positioning**\n",
      "\n",
      "**Tier 1 - Platform Leaders:**\n",
      "- **Microsoft/OpenAI**: Dominant with Azure OpenAI Service and Copilot ecosystem, leveraging enterprise relationships\n",
      "- **Google**: Competing through Bard, Vertex AI, and deep integration with Workspace\n",
      "- **Amazon**: AWS Bedrock positioning for enterprise deployment and scalability\n",
      "- **Anthropic**: Premium positioning with Claude for safety-conscious enterprises\n",
      "\n",
      "**Tier 2 - Specialized Players:**\n",
      "- **Salesforce**: Einstein GPT for CRM-specific applications\n",
      "- **ServiceNow**: AI agents for IT service management\n",
      "- **UiPath**: RPA + AI agent convergence\n",
      "- **Zendesk/Intercom**: Customer service specialization\n",
      "\n",
      "**Strategic Moats Being Built:**\n",
      "- Data network effects (training on proprietary datasets)\n",
      "- Enterprise integration depth\n",
      "- Vertical specialization\n",
      "- Safety and compliance frameworks\n",
      "\n",
      "### **Investment Patterns & Capital Flows**\n",
      "\n",
      "**Funding Landscape:**\n",
      "- **$50+ billion** invested in generative AI in 2023-2024\n",
      "- **Series A-B rounds**: $10-50M for specialized agent startups\n",
      "- **Growth rounds**: $100M+ for platform plays and vertical solutions\n",
      "- **Corporate venture**: Heavy investment from tech giants acquiring talent and IP\n",
      "\n",
      "**Strategic Investment Themes:**\n",
      "1. **Vertical-specific agents**: Healthcare, legal, finance commanding premium valuations\n",
      "2. **Enterprise infrastructure**: RAG systems, security, governance tools\n",
      "3. **Edge deployment**: Reducing cloud dependency and latency\n",
      "4. **Multi-agent orchestration**: Coordination and workflow platforms\n",
      "\n",
      "### **Enterprise Adoption Strategy Patterns**\n",
      "\n",
      "**Implementation Phases:**\n",
      "1. **Pilot Phase** (3-6 months): Limited use cases, proof of concept\n",
      "2. **Expansion Phase** (6-18 months): Department-wide deployment\n",
      "3. **"
     ]
    }
   ],
   "source": [
    "# During initialization\n",
    "agent = Agent(tools=[swarm])\n",
    "\n",
    "# Invocation through natural language\n",
    "result = str(agent(\n",
    "    \"Use a swarm of 4 agents to analyze the current market trend for generative ai based agents.\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The swarm tool implements a SharedMemory system that serves as a central knowledge repository for all agents in the swarm. This system maintains a thread-safe store where agents can record their contributions with metadata (including agent ID, content, phase, and timestamp). It tracks processing phases, allowing agents to retrieve only current-phase knowledge or access historical information. This shared memory architecture enables concurrent collaboration, maintains contribution history, and ensures smooth information flow between agentsâ€”all essential features for effective collective intelligence in a swarm.\n",
    "\n",
    "The full implementation of the swarm tool can be found in the [Strands Tools repository](https://github.com/strands-agents/tools/blob/main/src/strands_tools/swarm.py).\n",
    "\n",
    "Key Parameters\n",
    "- task: The main task to be processed by the swarm\n",
    "- swarm_size: Number of agents in the swarm (1-10)\n",
    "- coordination_pattern: How agents should coordinate\n",
    "  - collaborative: Agents build upon others' insights\n",
    "  - competitive: Agents develop independent solutions\n",
    "- hybrid: Balances cooperation with independent exploration\n",
    "\n",
    "How the Swarm Tool Works\n",
    "1. *Initialization*: Creates a swarm with shared memory and specialized agents\n",
    "2. *Phase Processing*: Agents work in parallel using ThreadPoolExecutor\n",
    "3. *Knowledge Sharing*: Agents store and retrieve information from shared memory\n",
    "4. *Result Collection*: Results from all agents are aggregated and presented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Swarm with Strands Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strands Agents SDK allows you to create swarms using existing Agent objects, even when they use different model providers or have different configurations. While various communication architectures are possible (hierarchical, parallel, sequential, and mesh), the following example demonstrates a mesh architecture implementation, which provides a flexible foundation for agent-to-agent communication.\n",
    "\n",
    "### 2.1 Mesh Swarm Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"./images/swarm_example.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a mesh architecture, all agents can communicate directly with each other. The following example demonstrates a swarm of specialized agents using mesh communication to solve problems collaboratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents with different expertise\n",
    "research_agent = Agent(system_prompt=(\"\"\"You are a Research Agent specializing in gathering and analyzing information.\n",
    "Your role in the swarm is to provide factual information and research insights on the topic.\n",
    "You should focus on providing accurate data and identifying key aspects of the problem.\n",
    "When receiving input from other agents, evaluate if their information aligns with your research.\n",
    "\"\"\"), \n",
    "callback_handler=None)\n",
    "\n",
    "creative_agent = Agent(system_prompt=(\"\"\"You are a Creative Agent specializing in generating innovative solutions.\n",
    "Your role in the swarm is to think outside the box and propose creative approaches.\n",
    "You should build upon information from other agents while adding your unique creative perspective.\n",
    "Focus on novel approaches that others might not have considered.\n",
    "\"\"\"), \n",
    "callback_handler=None)\n",
    "\n",
    "critical_agent = Agent(system_prompt=(\"\"\"You are a Critical Agent specializing in analyzing proposals and finding flaws.\n",
    "Your role in the swarm is to evaluate solutions proposed by other agents and identify potential issues.\n",
    "You should carefully examine proposed solutions, find weaknesses or oversights, and suggest improvements.\n",
    "Be constructive in your criticism while ensuring the final solution is robust.\n",
    "\"\"\"), \n",
    "callback_handler=None)\n",
    "\n",
    "summarizer_agent = Agent(system_prompt=\"\"\"You are a Summarizer Agent specializing in synthesizing information.\n",
    "Your role in the swarm is to gather insights from all agents and create a cohesive final solution.\n",
    "You should combine the best ideas and address the criticisms to create a comprehensive response.\n",
    "Focus on creating a clear, actionable summary that addresses the original query effectively.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh communication is implemented using a dictionary to track messages between agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to track messages between agents (mesh communication)\n",
    "messages = {\n",
    "    \"research\": [],\n",
    "    \"creative\": [],\n",
    "    \"critical\": [],\n",
    "    \"summarizer\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The swarm operates in multiple phases, with each agent first analyzing the problem independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generative Ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Initial analysis by each specialized agent\n",
    "research_result = research_agent(query)\n",
    "time.sleep(30)\n",
    "creative_result = creative_agent(query)\n",
    "time.sleep(30)\n",
    "critical_result = critical_agent(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial analysis, results are shared with all other agents (mesh communication):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share results with all other agents (mesh communication)\n",
    "messages[\"creative\"].append(f\"From Research Agent: {research_result}\")\n",
    "messages[\"critical\"].append(f\"From Research Agent: {research_result}\")\n",
    "messages[\"summarizer\"].append(f\"From Research Agent: {research_result}\")\n",
    "\n",
    "messages[\"research\"].append(f\"From Creative Agent: {creative_result}\")\n",
    "messages[\"critical\"].append(f\"From Creative Agent: {creative_result}\")\n",
    "messages[\"summarizer\"].append(f\"From Creative Agent: {creative_result}\")\n",
    "\n",
    "messages[\"research\"].append(f\"From Critical Agent: {critical_result}\")\n",
    "messages[\"creative\"].append(f\"From Critical Agent: {critical_result}\")\n",
    "messages[\"summarizer\"].append(f\"From Critical Agent: {critical_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second phase, each agent refines their solution based on input from all other agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Each agent refines based on input from others\n",
    "research_prompt = f\"{query}\\n\\nConsider these messages from other agents:\\n\" + \"\\n\\n\".join(messages[\"research\"])\n",
    "creative_prompt = f\"{query}\\n\\nConsider these messages from other agents:\\n\" + \"\\n\\n\".join(messages[\"creative\"])\n",
    "critical_prompt = f\"{query}\\n\\nConsider these messages from other agents:\\n\" + \"\\n\\n\".join(messages[\"critical\"])\n",
    "\n",
    "refined_research = research_agent(research_prompt)\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "refined_creative = creative_agent(creative_prompt)\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "refined_critical = critical_agent(critical_prompt)\n",
    "\n",
    "# Share refined results with summarizer\n",
    "messages[\"summarizer\"].append(f\"From Research Agent (Phase 2): {refined_research}\")\n",
    "messages[\"summarizer\"].append(f\"From Creative Agent (Phase 2): {refined_creative}\")\n",
    "messages[\"summarizer\"].append(f\"From Critical Agent (Phase 2): {refined_critical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the summarizer agent synthesizes all inputs into a comprehensive solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final phase: Summarizer creates the final solution\n",
    "time.sleep(30)\n",
    "\n",
    "summarizer_prompt = f\"\"\"\n",
    "Original query: {query}\n",
    "\n",
    "Please synthesize the following inputs from all agents into a comprehensive final solution:\n",
    "\n",
    "{\"\\n\\n\".join(messages[\"summarizer\"])}\n",
    "\n",
    "Create a well-structured final answer that incorporates the research findings, \n",
    "creative ideas, and addresses the critical feedback.\n",
    "\"\"\"\n",
    "\n",
    "final_solution = str(summarizer_agent(summarizer_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mesh architecture enables direct communication between all agents, allowing each agent to share insights with every other agent. The specialized roles (research, creative, critical, and summarizer) work together to produce a comprehensive solution that benefits from multiple perspectives and iterative refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Implementing Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the mesh communication example effectively demonstrates agent collaboration, a shared memory system would enhance the swarm's capabilities by providing:\n",
    "\n",
    "- A centralized knowledge repository for all agents\n",
    "- Automated phase tracking and historical knowledge preservation\n",
    "- Thread-safe concurrent access for improved efficiency\n",
    "- Persistent storage of insights across multiple interactions\n",
    "\n",
    "Extending our mesh swarm example with shared memory would replace the message dictionary with a SharedMemory instance, simplifying the code while enabling more sophisticated knowledge management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use Swarm:\n",
    "\n",
    "- For quick, parallel processing of a single complex task\n",
    "- When you need multiple perspectives on the same problem\n",
    "- For tasks that benefit from collective intelligence\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Multi-agent swarms solve complex problems through collective intelligence. The Strands Agents SDK supports both custom implementations and a built-in swarm tool with shared memory. By distributing tasks across specialized agents and enabling effective communication, swarms achieve better results than single agents working alone. Whether using mesh communication patterns or the swarm tool, developers can create systems where multiple agents work together with defined roles, coordination mechanisms, and knowledge sharing.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
